{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경영경제 카테고리 도서 추출 \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import re\n",
    "\n",
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "\n",
    "TTBKey = 'ttbseohyun13851618001'\n",
    "\n",
    "itemid_df = pd.read_csv('/Users/leeseohyun/Documents/GitHub/chack-it-out-2/item_id.csv')\n",
    "itemid_df.columns = ['index','itemid']\n",
    "itemid_df.drop('index',axis=1,inplace=True)\n",
    "itemid = itemid_df['itemid']\n",
    "\n",
    "text_list = []\n",
    "\n",
    "i=1\n",
    "\n",
    "for item in itemid:\n",
    "\n",
    "  \n",
    "  OptResult_array = 'previewImgList,fulldescription,Toc,categoryIdList'\n",
    "  product_lookup_url = f'http://www.aladin.co.kr/ttb/api/ItemLookUp.aspx?ttbkey={TTBKey}&itemIdType=ItemId&ItemId={item}&output=xml&Version=20131101&OptResult={OptResult_array}'\n",
    "  headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'}\n",
    "\n",
    "  try:\n",
    "    s = requests.Session()\n",
    "    s.headers.update(headers)\n",
    "\n",
    "    resp = requests_retry_session(session=s).get(product_lookup_url)\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "    i=i+1\n",
    "    if i%2000 == 0:\n",
    "      print(i)\n",
    "\n",
    "    title = soup.find_all('title')[-1].text\n",
    "    author = soup.find('author').text\n",
    "    pubdate = soup.find_all('pubdate')[1].text\n",
    "    description = soup.find('description').text\n",
    "    isbn13 = soup.find('isbn13').text\n",
    "    itemid = soup.select('item')[0]['itemid']\n",
    "    publisher = soup.find('publisher').text\n",
    "    fulldescription = soup.find('fulldescription').text\n",
    "    categoryname = soup.find('categoryname').text\n",
    "    itempage = soup.find('itempage').text\n",
    "    toc = soup.find('toc').text\n",
    "\n",
    "    toc = toc.replace('<BR>\\r\\n',' ').replace('<B>',' ').replace('</B>',' ').replace('<p>',' ').replace('</p>',' ')\n",
    "    toc = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9]\", \" \", toc)\n",
    "    toc = re.sub(r\"\\s+\", \" \", toc).strip()\n",
    "  \n",
    "\n",
    "    try:\n",
    "      previewimg = soup.find('previewimglist').find('previewimg').text\n",
    "    except:\n",
    "      previewimg = '표지 없음'\n",
    "  \n",
    "\n",
    "    paprams = [title,author,pubdate,description,isbn13,itemid,publisher,fulldescription,categoryname,itempage,toc,previewimg]\n",
    "    text_list.append(paprams)\n",
    "\n",
    "  except Exception as ex:\n",
    "    print(f\"exception occured : {ex}\")\n",
    "    continue\n",
    "\n",
    "\n",
    "df = pd.DataFrame(text_list, columns = ['title','author','pubdate','description','isbn13','itemid','publisher','fulldescription','categoryname','itempage','toc','previewimg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72850 entries, 0 to 72849\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            72850 non-null  object\n",
      " 1   author           72850 non-null  object\n",
      " 2   pubdate          72850 non-null  object\n",
      " 3   description      72850 non-null  object\n",
      " 4   isbn13           72850 non-null  object\n",
      " 5   itemid           72850 non-null  object\n",
      " 6   publisher        72850 non-null  object\n",
      " 7   fulldescription  72850 non-null  object\n",
      " 8   categoryname     72850 non-null  object\n",
      " 9   itempage         72850 non-null  object\n",
      " 10  toc              72850 non-null  object\n",
      " 11  previewimg       72850 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./pre_toc_me.csv',index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"pre_toc_me.pickle\",\"wb\") as f:\n",
    "    pickle.dump(df, f)  \n",
    " \n",
    "with open(\"pre_toc_me.pickle\",\"rb\") as fi:\n",
    "    test = pickle.load(fi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자기계발 카테고리 도서 추출 \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import re\n",
    "\n",
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "\n",
    "TTBKey = 'ttboilehot09101432001'\n",
    "\n",
    "itemid_df = pd.read_csv('/Users/leeseohyun/Documents/GitHub/chack-it-out-2/self_improvement_id.csv')\n",
    "itemid_df.columns = ['index','itemid']\n",
    "itemid_df.drop('index',axis=1,inplace=True)\n",
    "itemid = itemid_df['itemid']\n",
    "\n",
    "text_list = []\n",
    "\n",
    "i=1\n",
    "\n",
    "for item in itemid:\n",
    "\n",
    "  \n",
    "  OptResult_array = 'previewImgList,fulldescription,Toc,categoryIdList'\n",
    "  product_lookup_url = f'http://www.aladin.co.kr/ttb/api/ItemLookUp.aspx?ttbkey={TTBKey}&itemIdType=ItemId&ItemId={item}&output=xml&Version=20131101&OptResult={OptResult_array}'\n",
    "  headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'}\n",
    "\n",
    "  try:\n",
    "    s = requests.Session()\n",
    "    s.headers.update(headers)\n",
    "\n",
    "    resp = requests_retry_session(session=s).get(product_lookup_url)\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "    i=i+1\n",
    "    if i%2000 == 0:\n",
    "      print(i)\n",
    "\n",
    "    title = soup.find_all('title')[-1].text\n",
    "    author = soup.find('author').text\n",
    "    pubdate = soup.find_all('pubdate')[1].text\n",
    "    description = soup.find('description').text\n",
    "    isbn13 = soup.find('isbn13').text\n",
    "    itemid = soup.select('item')[0]['itemid']\n",
    "    publisher = soup.find('publisher').text\n",
    "    fulldescription = soup.find('fulldescription').text\n",
    "    categoryname = soup.find('categoryname').text\n",
    "    itempage = soup.find('itempage').text\n",
    "    toc = soup.find('toc').text\n",
    "\n",
    "    toc = toc.replace('<BR>\\r\\n',' ').replace('<B>',' ').replace('</B>',' ').replace('<p>',' ').replace('</p>',' ')\n",
    "    toc = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9]\", \" \", toc)\n",
    "    toc = re.sub(r\"\\s+\", \" \", toc).strip()\n",
    "  \n",
    "\n",
    "    try:\n",
    "      previewimg = soup.find('previewimglist').find('previewimg').text\n",
    "    except:\n",
    "      previewimg = '표지 없음'\n",
    "  \n",
    "\n",
    "    paprams = [title,author,pubdate,description,isbn13,itemid,publisher,fulldescription,categoryname,itempage,toc,previewimg]\n",
    "    text_list.append(paprams)\n",
    "\n",
    "  except Exception as ex:\n",
    "    print(f\"exception occured : {ex}\")\n",
    "    continue\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(text_list, columns = ['title','author','pubdate','description','isbn13','itemid','publisher','fulldescription','categoryname','itempage','toc','previewimg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./pre_toc_self.csv',index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"pre_toc_self.pickle\",\"wb\") as a:\n",
    "    pickle.dump(df1, a)  \n",
    " \n",
    "with open(\"pre_toc_self.pickle\",\"rb\") as ai:\n",
    "    test1 = pickle.load(ai) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
